---
title: "Ch05 Advanced HTML Parsing"
category:
 - Programming
tag:
 - Python
 - Web Scraping
---

## 1. Another Serving of BeautifulSoup

```python
"""
05.1.py
find tags
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen("http://www.pythonscraping.com/pages/warandpeace.html")
bs = BeautifulSoup(html.read(), "html.parser")

# find_all(tagName, tagAttributes)
name_list = bs.find_all("span", {"class": "green"})
for name in name_list:
    print(name.get_text())  # get content of tag

```

`get_text()` strips all tags from the document you are working with. Calling `get_text()` should always be the last thing you do.

### 1.1 find() and find_all()

```python
# find all matched tags
find_all(tag, attrs, recursive, text, limit, **kwargs)
# find first matched tag
find(tag, attrs, recursive, text, **kwargs)
```

- `tag`: name of the tag, you can pass a list of tag names

  ```
  find_all(["h1", "h2", "h3"])
  ```

- `attrs`: dict of attributes and values

  ```
  find_all("span", {"class": ["green","red"]})
  ```

- `recursive`: boolean, default to True. If it is:

  - True:  looks into children recursively.
  - False: only matches the top-level tags

- `text`: matches based on the text content of the tags

  ```
  find_all(text="the prince")
  ```

- `limit`: matches only first x items from the page

- `kwarg`: named arguments

  ```
  find_all(id="title", class_="text")
  ```

## 2. Navigating Trees

### 2.1 Children and Descendants

- children: exactly one tag below a parent
- descendants: any level in the tree below a parent

```python
"""
05.2.py
children and descendants
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen("http://www.pythonscraping.com/pages/page3.html")
bs = BeautifulSoup(html.read(), "html.parser")


# get children
print("\033[31mChildren:\033[0m")
for child in bs.find("table", {"id": "giftList"}).children:
    print(child)

# get siblings
print("\033[31mSiblings:\033[0m")
# next_siblings return all siblings of an object without the object itself
for sibling in bs.find("table", {"id": "giftList"}).tr.next_siblings:
    print(sibling)

```

### 2.2 parents

```python
# get parents
# parent() and parents()
print(
    bs.find("img", {"src": "../img/gifts/img1.jpg"}).parent.previous_sibling.get_text()
)

```

## 3 Regular Expressions

```python
"""
05.3.py
Regular Expressions
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup

import re

html = urlopen("http://www.pythonscraping.com/pages/page3.html")
bs = BeautifulSoup(html, "html.parser")

# matches regexp ../img/gifts/img.*\.jpg
images = bs.find_all("img", {"src": re.compile(r"../img/gifts/img.*\.jpg")})

for image in images:
    # access attributes
    print(image.attrs)
    # using attr name
    print(image.attrs["src"])
    # simple way
    print(image["src"])

```

## 4. Lambda Expressions

```python
"""
05.4.py
Lambda Expressions
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup


# lambda expression
squares = lambda n: n**2
print(squares(3))

url = "http://www.pythonscraping.com/pages/page3.html"
html = urlopen(url)
bs = BeautifulSoup(html, "html.parser")

# find tags that have 2 attrs
tags = bs.find_all(lambda tag: len(tag.attrs) == 2)
print(tags)

```

